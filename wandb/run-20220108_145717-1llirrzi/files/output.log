GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
  | Name      | Type             | Params
-----------------------------------------------
0 | conv1     | Conv2d           | 80
1 | pool      | MaxPool2d        | 0
2 | conv2     | Conv2d           | 1.2 K
3 | fc1       | Linear           | 13.3 K
4 | criterion | CrossEntropyLoss | 0
5 | train_acc | Accuracy         | 0
6 | val_acc   | Accuracy         | 0
7 | test_acc  | Accuracy         | 0
-----------------------------------------------
14.6 K    Trainable params
0         Non-trainable params
14.6 K    Total params
0.058     Total estimated model params size (MB)

Validation sanity check:   0%|                                                                                                                                   | 0/2 [00:00<?, ?it/s]average val loss 2.5809913873672485
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Epoch 0:   1%|▉                                                                                                                 | 4/517 [00:00<00:15, 33.79it/s, loss=2.63, v_num=rrzi]
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.





Epoch 0:  84%|███████████████████████████████████████████████████████████████████████████████████████████▉                 | 436/517 [00:12<00:02, 35.64it/s, loss=0.00479, v_num=rrzi]






Epoch 1:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 481/517 [00:13<00:01, 35.58it/s, loss=0.00356, v_num=rrzi]







Epoch 2:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 507/517 [00:14<00:00, 34.42it/s, loss=0.0018, v_num=rrzi]average val loss 0.022735240418202716






Epoch 3:  85%|██████████████████████████████████████████████████████████████████████████████████████████████                | 442/517 [00:14<00:02, 29.83it/s, loss=0.0156, v_num=rrzi]








Epoch 4:  98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 507/517 [00:16<00:00, 31.10it/s, loss=2.61e-05, v_num=rrzi]average val loss 0.01282985334877819







Epoch 5:  88%|███████████████████████████████████████████████████████████████████████████████████████████████             | 455/517 [00:16<00:02, 28.26it/s, loss=0.000762, v_num=rrzi]








Epoch 6:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 507/517 [00:16<00:00, 30.61it/s, loss=0.0182, v_num=rrzi]average val loss 0.044102677638562376







Epoch 7:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 481/517 [00:16<00:01, 29.30it/s, loss=0.000263, v_num=rrzi]









Epoch 8:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████▊          | 468/517 [00:19<00:01, 24.57it/s, loss=4.87e-05, v_num=rrzi]










Epoch 9:  98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 507/517 [00:20<00:00, 24.16it/s, loss=0.000209, v_num=rrzi]average val loss 0.022233651731268414
Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [00:21<00:00, 24.38it/s, loss=0.000209, v_num=rrzi]