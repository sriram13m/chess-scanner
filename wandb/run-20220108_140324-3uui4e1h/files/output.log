GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
  | Name      | Type             | Params
-----------------------------------------------
0 | conv1     | Conv2d           | 80
1 | pool      | MaxPool2d        | 0
2 | conv2     | Conv2d           | 1.2 K
3 | fc1       | Linear           | 13.3 K
4 | criterion | CrossEntropyLoss | 0
5 | train_acc | Accuracy         | 0
6 | val_acc   | Accuracy         | 0
7 | test_acc  | Accuracy         | 0
-----------------------------------------------
14.6 K    Trainable params
0         Non-trainable params
14.6 K    Total params
0.058     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

Validation sanity check:   0%|                                                                                                                                   | 0/2 [00:00<?, ?it/s]average val loss 2.582005500793457
Epoch 0:   8%|████████▍                                                                                                       | 39/517 [00:01<00:17, 26.81it/s, loss=0.177, v_num=4e1h]
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.







Epoch 0:  85%|█████████████████████████████████████████████████████████████████████████████████████████████▌                | 440/517 [00:17<00:03, 24.97it/s, loss=0.0031, v_num=4e1h]







Epoch 1:  88%|███████████████████████████████████████████████████████████████████████████████████████████████▌             | 453/517 [00:14<00:02, 31.12it/s, loss=0.00372, v_num=4e1h]







Epoch 2:  85%|█████████████████████████████████████████████████████████████████████████████████████████████▏               | 442/517 [00:15<00:02, 28.23it/s, loss=0.00103, v_num=4e1h]

Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [00:16<00:00, 30.68it/s, loss=0.00103, v_num=4e1h]