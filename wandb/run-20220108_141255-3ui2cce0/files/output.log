GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
  | Name      | Type             | Params
-----------------------------------------------
0 | conv1     | Conv2d           | 80
1 | pool      | MaxPool2d        | 0
2 | conv2     | Conv2d           | 1.2 K
3 | fc1       | Linear           | 13.3 K
4 | criterion | CrossEntropyLoss | 0
5 | train_acc | Accuracy         | 0
6 | val_acc   | Accuracy         | 0
7 | test_acc  | Accuracy         | 0
-----------------------------------------------
14.6 K    Trainable params
0         Non-trainable params
14.6 K    Total params
0.058     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

Validation sanity check:   0%|                                                                                                                                   | 0/2 [00:00<?, ?it/s]average val loss 2.55882728099823
Epoch 0:   9%|█████████▉                                                                                                     | 46/517 [00:01<00:15, 30.42it/s, loss=0.0713, v_num=cce0]
/Users/fevenz/miniforge3/envs/chess_scanner/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.






Epoch 0:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 511/517 [00:15<00:00, 33.46it/s, loss=0.00024, v_num=cce0]average val loss 0.008578290731102537






Epoch 1:  84%|███████████████████████████████████████████████████████████████████████████████████████████                 | 436/517 [00:14<00:02, 30.91it/s, loss=2.36e-05, v_num=cce0]







Epoch 2:  86%|██████████████████████████████████████████████████████████████████████████████████████████████▍               | 444/517 [00:15<00:02, 28.58it/s, loss=0.0129, v_num=cce0]

Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [00:16<00:00, 31.06it/s, loss=0.0129, v_num=cce0]